{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trash Object Detection Using YOLOv8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is comparised of several components to deploy an trash detection model using YOLOv5 and YOLOv8. The notebook includes the following: (1) Installation and Setup of YOLOv5 and YOLOv8, (2) Downloading the TACO Dataset, (3) Preprocessing the Data, (4) Model Training with YOLOv5 and YOLOv8, (5) YOLO Model Evaluation, and (6) Trash Detection Model Deployment.\n",
    "<br>\n",
    "<br>\n",
    "Objective(s): Build and train a Custom YOLOv8 Model on the TACO dataset to recognize various types of trash. Create custom Python scripts to deploy the YOLOv8 model on the Freenove Tank Robot that: (a) implement real-time trash detection using the robot's camera and the trained model and (b) program the robot to move towards and pick-up trash if detected or keep searching for trash if no trash was detected. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLOv5/YOLOv8\n",
    "For information on installation and preperation, see https://github.com/mattiegisselbeck/trash-detection."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-- Terminal --\n",
    "git clone https://github.com/ultralytics/yolov5 \n",
    "\n",
    "# Create Andaconda Environment for YOLOv5 and YOLOv8\n",
    "conda create --name yolov5 python=3.8 # YOLOv5 requires Python 3.8\n",
    "conda activate yolov8\n",
    "\n",
    "# Install Requirements for YOLOv5 and YOLOv8\n",
    "cd /Users/mattiegisselbeck/yolov5\n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TACO"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-- Terminal --\n",
    "git clone https://github.com/pedropro/TACO\n",
    "\n",
    "# Install Requirements\n",
    "pip3 install -r requirements.txt \n",
    "pip3 install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI\n",
    "\n",
    "# Download Dataset\n",
    "!python3 download.py\n",
    "\n",
    "# Split Dataset\n",
    "python3 split_dataset.py --dataset_dir ../data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run YOLOv5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run YOLOv8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Model                                                                                | size<br><sup>(pixels) | mAP<sup>val<br>50-95 | Speed<br><sup>CPU ONNX<br>(ms) | Speed<br><sup>A100 TensorRT<br>(ms) | params<br><sup>(M) | FLOPs<br><sup>(B) |\n",
    "| ------------------------------------------------------------------------------------ | --------------------- | -------------------- | ------------------------------ | ----------------------------------- | ------------------ | ----------------- |\n",
    "| [YOLOv8x](https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x.pt) | 640                   | 53.9                 | 479.1                          | 3.53                                | 68.2               | 257.8             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model                                                                                | size<br><sup>(pixels) | mAP<sup>val<br>50-95 | Speed<br><sup>CPU ONNX<br>(ms) | Speed<br><sup>A100 TensorRT<br>(ms) | params<br><sup>(M) | FLOPs<br><sup>(B) |\n",
    "| ------------------------------------------------------------------------------------ | --------------------- | -------------------- | ------------------------------ | ----------------------------------- | ------------------ | ----------------- |\n",
    "| [YOLOv8n](https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt) | 640                   | 37.3                 | 80.4                           | 0.99                                | 3.2                | 8.7               |\n",
    "| [YOLOv8s](https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt) | 640                   | 44.9                 | 128.4                          | 1.20                                | 11.2               | 28.6              |\n",
    "| [YOLOv8m](https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m.pt) | 640                   | 50.2                 | 234.7                          | 1.83                                | 25.9               | 78.9              |\n",
    "| [YOLOv8x](https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x.pt) | 640                   | 53.9                 | 479.1                          | 3.53                                | 68.2               | 257.8             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Build Model\n",
    "model = YOLO(\"/Users/mattiegisselbeck/Documents/GitHub/trashbot/runs/detect/train4/weights/best.pt\") \n",
    "\n",
    "# Train YOLOv8\n",
    "results = model.train(data=\"./data.yaml\", epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"/Users/mattiegisselbeck/Documents/GitHub/trashbot/runs/detect/train5/weights/best.pt\") \n",
    "\n",
    "results = model(\"/Users/mattiegisselbeck/Desktop/000013.JPG\")  # Predict (Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLOv8 on Freenove Robot / Raspberry Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pigpio\n",
    "from camera import Camera\n",
    "from motor import Motor\n",
    "from infrared import Infrared\n",
    "\n",
    "class TrashBot:\n",
    "    def __init__(self):\n",
    "        # Initialize pigpio\n",
    "        os.system(\"sudo pigpiod\")\n",
    "        time.sleep(1)  # Wait for pigpiod to initialize\n",
    "\n",
    "        # Initialize components\n",
    "        self.camera = Camera()\n",
    "        self.motor = Motor()\n",
    "        self.infrared = Infrared()\n",
    "\n",
    "    def detect_trash(self):\n",
    "        while True:\n",
    "            trash_detected, distance = self.camera.look_for_trash()\n",
    "\n",
    "            if not trash_detected:\n",
    "                self.motor.move_forward(6)  # Move forward 6 inches\n",
    "            else:\n",
    "                self.motor.move_distance(distance)  # Move towards the trash\n",
    "                self.motor.pick_up_trash()\n",
    "                self.motor.drop_trash()\n",
    "\n",
    "                # After handling the trash, loop back to start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "# Capture a JPEG while still running in the preview mode. When you\n",
    "# capture to a file, the return value is the metadata for that image.\n",
    "import time\n",
    "from picamera2 import Picamera2, Preview\n",
    "from libcamera import Transform\n",
    "picam2 = Picamera2()\n",
    "preview_config = picam2.create_preview_configuration(main={\"size\": (640, 480)},transform=Transform(hflip=1,vflip=1))\n",
    "picam2.configure(preview_config)\n",
    "picam2.start_preview(Preview.QTGL)\n",
    "picam2.start()\n",
    "time.sleep(2)\n",
    "metadata = picam2.capture_file(\"image.jpg\")\n",
    "print(metadata)\n",
    "picam2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_trash():\n",
    "    picam2 = Picamera2()\n",
    "    preview_config = picam2.create_preview_configuration(main={\"size\": (640, 480)},transform=Transform(hflip=1,vflip=1))\n",
    "    picam2.configure(preview_config)\n",
    "    picam2.start_preview(Preview.QTGL)\n",
    "    picam2.start()\n",
    "    time.sleep(2)\n",
    "    metadata = picam2.capture_file(\"image.jpg\")\n",
    "    print(metadata)\n",
    "    picam2.close()\n",
    "    \n",
    "    # Detect \n",
    "    model = YOLO(\"/Users/mattiegisselbeck/Documents/GitHub/trashbot/runs/detect/train4/weights/best.pt\") \n",
    "    results = model(\"/path/to/image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ultrasonic:\n",
    "    def __init__(self):        \n",
    "        GPIO.setwarnings(False)        \n",
    "        self.trigger_pin = 27\n",
    "        self.echo_pin = 22\n",
    "        self.MAX_DISTANCE = 300               # define the maximum measuring distance, unit: cm\n",
    "        self.timeOut = self.MAX_DISTANCE*60   # calculate timeout according to the maximum measuring distance\n",
    "        GPIO.setmode(GPIO.BCM)\n",
    "        GPIO.setup(self.trigger_pin,GPIO.OUT)\n",
    "        GPIO.setup(self.echo_pin,GPIO.IN)\n",
    "\n",
    "    def detect_trash(self, image_path):\n",
    "        # Use the model to detect objects in the image\n",
    "        results = model(image_path)\n",
    "\n",
    "        # Check if any detected object is labeled as 'trash'\n",
    "        for detection in results.xyxy[0]:  # results.xyxy[0] contains the bounding box coordinates and class\n",
    "            if detection[-1] == self.trash_class_id:  # Assuming you know the class ID for trash\n",
    "                return True  # Trash is detected\n",
    "        return False  # No trash detected\n",
    "\n",
    "    def run_motor(self, distance, towards_trash=False):\n",
    "        # ... (existing logic with an added condition for moving towards trash)\n",
    "\n",
    "    def run(self):\n",
    "        self.PWM=Motor()\n",
    "        while True:\n",
    "            image_path = '/path/to/image.jpg'  # Update with the actual image path or method to capture image\n",
    "            if self.detect_trash(image_path):\n",
    "                # If trash is detected, move a certain distance towards it\n",
    "                # You might want to calculate this distance based on the size or position of the trash in the image\n",
    "                self.run_motor(None, towards_trash=True)\n",
    "            else:\n",
    "                # If no trash is detected, continue normal operation\n",
    "                distance = self.get_distance()\n",
    "                self.run_motor(distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RPi.GPIO as GPIO\n",
    "import time\n",
    "from Motor import *\n",
    "from servo import *\n",
    "\n",
    "class Ultrasonic:\n",
    "    def __init__(self):        \n",
    "        GPIO.setwarnings(False)        \n",
    "        self.trigger_pin = 27\n",
    "        self.echo_pin = 22\n",
    "        self.MAX_DISTANCE = 300               # define the maximum measuring distance, unit: cm\n",
    "        self.timeOut = self.MAX_DISTANCE*60   # calculate timeout according to the maximum measuring distance\n",
    "        GPIO.setmode(GPIO.BCM)\n",
    "        GPIO.setup(self.trigger_pin,GPIO.OUT)\n",
    "        GPIO.setup(self.echo_pin,GPIO.IN)\n",
    "        \n",
    "    def pulseIn(self,pin,level,timeOut): # obtain pulse time of a pin under timeOut\n",
    "        t0 = time.time()\n",
    "        while(GPIO.input(pin) != level):\n",
    "            if((time.time() - t0) > timeOut*0.000001):\n",
    "                return 0;\n",
    "        t0 = time.time()\n",
    "        while(GPIO.input(pin) == level):\n",
    "            if((time.time() - t0) > timeOut*0.000001):\n",
    "                return 0;\n",
    "        pulseTime = (time.time() - t0)*1000000\n",
    "        return pulseTime\n",
    "    \n",
    "    def get_distance(self):     # get the measurement results of ultrasonic module,with unit: cm\n",
    "        distance_cm2=[0.0,0.0,0.0,0.0,0.0]\n",
    "        for i in range(5):\n",
    "            GPIO.output(self.trigger_pin,GPIO.HIGH)      # make trigger_pin output 10us HIGH level \n",
    "            time.sleep(0.00001)     # 10us\n",
    "            GPIO.output(self.trigger_pin,GPIO.LOW) # make trigger_pin output LOW level \n",
    "            pingTime = self.pulseIn(self.echo_pin,GPIO.HIGH,self.timeOut)   # read plus time of echo_pin\n",
    "            distance_cm2[i] = pingTime * 340.0 / 2.0 / 10000.0     # calculate distance with sound speed 340m/s\n",
    "        distance_cm2=sorted(distance_cm2)\n",
    "        return  distance_cm2[2]\n",
    "    \n",
    "    def run_motor(self,distance):\n",
    "        if(distance!=0):\n",
    "            if distance < 45 :\n",
    "                self.PWM.setMotorModel(-1500,-1500) #Back\n",
    "                time.sleep(0.4)\n",
    "                self.PWM.setMotorModel(-1500,1500)  #Left\n",
    "                time.sleep(0.2)         \n",
    "            else :\n",
    "                self.PWM.setMotorModel(1500,1500)   #Forward\n",
    "            \n",
    "    def run(self):\n",
    "        self.PWM=Motor()\n",
    "        while True:\n",
    "            distance = self.get_distance()\n",
    "            time.sleep(0.2)\n",
    "            #print (\"The distance is \"+str(distance)+\"CM\")\n",
    "            self.run_motor(distance)\n",
    "\n",
    "ultrasonic=Ultrasonic()         \n",
    "if __name__ == '__main__':     # Program entrance\n",
    "    print ('Program is starting...')\n",
    "    servo=Servo()\n",
    "    servo.setServoPwm('0',90)\n",
    "    servo.setServoPwm('1',140)\n",
    "    try:\n",
    "        ultrasonic.run()\n",
    "    except KeyboardInterrupt:  # When 'Ctrl+C' is pressed, the child program destroy() will be  executed.\n",
    "        PWM.setMotorModel(0,0)\n",
    "        servo.setServoPwm('0',90)\n",
    "        servo.setServoPwm('1',140)\n",
    "        print (\"\\nEnd of program\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import time\n",
    "from picamera2 import Picamera2, Preview\n",
    "from libcamera import Transform\n",
    "\n",
    "def find_trash\n",
    "    picam2 = Picamera2()\n",
    "    preview_config = picam2.create_preview_configuration(main={\"size\": (640, 480)},transform=Transform(hflip=1,vflip=1))\n",
    "    picam2.configure(preview_config)\n",
    "    picam2.start_preview(Preview.QTGL)\n",
    "    picam2.start()\n",
    "    time.sleep(2)\n",
    "    metadata = picam2.capture_file(\"image.jpg\")\n",
    "    print(metadata)\n",
    "    picam2.close()\n",
    "    \n",
    "    # Detect \n",
    "    model = YOLO(\"/Users/mattiegisselbeck/Documents/GitHub/trashbot/runs/detect/train4/weights/best.pt\") \n",
    "    results = model(/path/to/image.jpg\")\n",
    "\n",
    "    if trash is detected\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "use camera to look for trash (YOLOv8)\n",
    "        if no trash is detected \n",
    "            then move forward 6 inches \n",
    "        if trash is detected \n",
    "            then calculate the distance to move towards the trash \n",
    "            and then move that distance\n",
    "            and then pick-up trash and move it\n",
    "            once object is picked-up > drop it\n",
    "\n",
    "            loop back to the start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook represents a MVP of Trashbot since it holds all the necessary components to deploy, train, and test an trash detection model using YOLOv5 or YOLOv8 and the TACO dataset. A majority of the notebook is written in CLI to allow for simplicity and efficency and that we are able to create a custom conda environment for Trashbot. The notebook also covers CLI instructions on how to download the TACO dataset, download its requirements, and split the dataset for training for the YOLO models. Additionally, the notebook clones the YOLOv5 Github repository, installs ultralytics (necessary for YOLO), builds a new YOLO model, and trains a YOLO model. Near the end of the notebook, there is a draft version of the script that will be used for deploying the YOLOv8 model onto the Freenove robot (Trashbot)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
